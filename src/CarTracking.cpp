#include <iostream>
#include "opencv2/opencv.hpp" 
#include "opencv2/core/core.hpp"  
#include "opencv2/highgui/highgui.hpp"  
#include "opencv2/video/background_segm.hpp"
#include "tracker/BlobTracking.hpp"  
#include "motion/MotionTracker.hpp"  
#include "opencv2/imgproc/imgproc.hpp"
#include "opencv2/video/video.hpp"

using namespace cv;
using namespace cvb;  
using namespace std;  
  
  
int main(int argc, const char* argv[])  
{  

	const int MAX_SIZE = 500;
  
	 //global variables  
	 Mat frame; //current frame  
	 Mat fgMaskMOG; //fg mask generated by MOG method  
  
  
	 Ptr<BackgroundSubtractor> pMOG; //MOG Background subtractor  
	 pMOG = new BackgroundSubtractorMOG();  

	  /* Blob Tracking Algorithm */
	  Mat  img_blob; 
	  BlobTracking* blobTracking;
	  blobTracking = new BlobTracking;

	  /* Motion detector */
	  MotionTracker* tracker;
	  tracker = new MotionTracker;


 string fileName = argv[1]; 
 cout << fileName << endl;
 VideoCapture stream1(fileName);   //0 is the id of video device.0 if you have only one camera     
  
 Mat element = getStructuringElement(MORPH_RECT, Size(3, 3), Point(1,1) );     
 Mat img_mask;

  // we need a first frame to configure points if not defined
  stream1.read(frame);
  bool mustResize = ((frame.size().width/2) > MAX_SIZE) ? 1 : 0;

  tracker->init(frame, fileName);
  double fps = stream1.get(CV_CAP_PROP_FPS);
  long frames  = 0;
  cout << fps << " fps " << endl;

 //unconditional loop     
 while (true) {     

  if(!(stream1.read(frame))){
	cout << "Cannot read the frame" << endl;
	break; 

  } //get one frame form video    
	  
  if (mustResize)
	resize(frame, frame, Size(frame.size().width/2, frame.size().height/2) );  

  //medianBlur(frame, frame, 11);
  pMOG->operator()(frame, fgMaskMOG);
  
  if ( !fgMaskMOG.empty())
  {
	blobTracking->process(frame, fgMaskMOG, img_blob);
	tracker->setTracks(blobTracking->getTracks());
	tracker->detect(frame,frames, fps);

  }
  
  if (waitKey(1) >= 0)     
   break;     
 }

 return 0;
  
}  